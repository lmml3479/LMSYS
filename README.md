For medicinal, environmental, and technological applications, large-language models (LLMs) have become preeminent. 
To further successful human-computer interactions, Kaggle launched the 2024 LMSYS competition.
The goal is to create a model that predicts what response from LLMs humans prefer.
The training dataset is collected from Chatbot Arena, in which users chat with two anonymous LLMs and choose the answer they prefer.
This challenge aligns with the concept of "reward models" or "preference models" in reinforcement learning from human feedback (RLHF). 
Previous research has identified limitations in directly prompting an existing LLM for preference predictions. 
These limitations often stem from biases such as position bias, verbosity bias, or self-enhancement bias.
Creating a novel model that is able to select the "correct LLM response" with limited inherent prejudice has the potential to revolutionize LLMs,
and their application in day-to-day life.
